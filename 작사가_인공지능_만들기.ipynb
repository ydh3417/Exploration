{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEsQMvNIWq08",
        "outputId": "2392fd2c-13a9-4fbb-8ae9-188b3dc10a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Xr3QDPZKUN",
        "outputId": "b02826f4-7ab0-4167-d5c2-baa881940411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187089\n",
            "Examples:\n",
            " ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"
          ]
        }
      ],
      "source": [
        "import re    \n",
        "import glob\n",
        "import numpy as np         \n",
        "import tensorflow as tf    \n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "txt_file_path = (\"/content/drive/MyDrive/Colab Notebooks/lyricist/*\")\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "for txt_file in txt_list:\n",
        "  with open(txt_file, \"r\") as f:\n",
        "    raw = f.read().splitlines()\n",
        "    raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjMkY3ShZc5t",
        "outputId": "5c10cbb1-efe7-4dc4-9333-df98eb07bf8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for some education\n",
            "Made my way into the night\n",
            "All that bullshit conversation\n",
            "Baby, can't you read the signs? I won't bore you with the details, baby\n",
            "I don't even wanna waste your time\n",
            "Let's just say that maybe\n",
            "You could help me ease my mind\n",
            "I ain't Mr. Right But if you're looking for fast love\n",
            "If that's love in your eyes\n",
            "It's more than enough\n"
          ]
        }
      ],
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue \n",
        "    if idx >9: break \n",
        "        \n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uiQFJVJVHJ6S"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()   \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) \n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'      \n",
        "    \n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZXk9xaGHL-p",
        "outputId": "96826211-2e40-48d5-e1b5-ad28a76336f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> looking for some education <end>',\n",
              " '<start> made my way into the night <end>',\n",
              " '<start> all that bullshit conversation <end>',\n",
              " '<start> baby , can t you read the signs ? i won t bore you with the details , baby <end>',\n",
              " '<start> i don t even wanna waste your time <end>',\n",
              " '<start> let s just say that maybe <end>',\n",
              " '<start> you could help me ease my mind <end>',\n",
              " '<start> i ain t mr . right but if you re looking for fast love <end>',\n",
              " '<start> if that s love in your eyes <end>',\n",
              " '<start> it s more than enough <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "  if len(sentence) == 0: continue\n",
        "  if sentence[-1] == \":\": continue\n",
        "\n",
        "  corpus.append(preprocess_sentence(sentence))\n",
        "\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3wgZG7c56s",
        "outputId": "9b2868c9-c8f2-4cd4-a3b8-8bbd4bec2c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    2   304    28 ...     0     0     0]\n",
            " [    2   221    13 ...     0     0     0]\n",
            " [    2    24    17 ...     0     0     0]\n",
            " ...\n",
            " [    2    13   440 ...     0     0     0]\n",
            " [    2    26    17 ...     0     0     0]\n",
            " [    4  1644 10643 ...     4  4669     3]] <keras_preprocessing.text.Tokenizer object at 0x7f7408576d50>\n"
          ]
        }
      ],
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=15000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=20)  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLtFI4-QMjN",
        "outputId": "88358266-898a-435a-a2c5-45a26b782733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ],
      "source": [
        "for idx in tokenizer.index_word:\n",
        "  print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "  if idx>=10: break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Orl_Ex9QmH7",
        "outputId": "c3520320-ca21-4944-c572-f7b7854afaa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2  304   28   99 4812    3    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "[ 304   28   99 4812    3    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "src_input = tensor[:, :-1]\n",
        "tgt_input = tensor[:, 1:]\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O9T-BOwZRL0I"
      },
      "outputs": [],
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqKNab_SSwo_",
        "outputId": "07662788-a6f7-44a1-bf2b-169e6c664261"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 19), dtype=tf.int32, name=None), TensorSpec(shape=(256, 19), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "BUFFER_SIZE = len(enc_train)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        "VOCAB_SIZE = tokenizer.num_words + 1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtQ2aVpAU4X7",
        "outputId": "1cf478ea-077c-4394-c64e-5a4a44afdc5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 19), dtype=tf.int32, name=None), TensorSpec(shape=(256, 19), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(steps_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XICjtJcFWHz0",
        "outputId": "335d78b9-d176-49a2-d8ad-1c40ae1717a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKf49HvQVMux",
        "outputId": "26829373-ac57-4a36-b91f-4b94a2822a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Train (140600, 19)\n",
            "Target Train (140600, 19)\n"
          ]
        }
      ],
      "source": [
        "print(\"Source Train\", enc_train.shape)\n",
        "print(\"Target Train\", dec_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8olgZGHVtQk"
      },
      "source": [
        "# 인공지능 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8vEmJ-XwBBpU"
      },
      "outputs": [],
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super(TextGenerator, self).__init__()\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "embedding_size = 512\n",
        "hidden_size = 2048\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-iUAaxABacc",
        "outputId": "87daf29b-cbca-4009-d759-f00514f5bc9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 19, 15001), dtype=float32, numpy=\n",
              "array([[[-4.65645018e-04,  2.70456192e-04,  2.13819541e-04, ...,\n",
              "         -1.05143808e-04,  4.81698735e-05, -1.27589170e-04],\n",
              "        [-7.87454192e-04,  3.09480733e-04,  2.78743508e-04, ...,\n",
              "          7.78614121e-05,  4.11331894e-05, -1.31556852e-04],\n",
              "        [-9.02497210e-04,  1.92304447e-04,  3.82778584e-04, ...,\n",
              "          2.07989706e-05, -2.34694395e-04,  1.05635963e-05],\n",
              "        ...,\n",
              "        [-2.26701517e-03, -3.58482986e-03, -1.29570928e-03, ...,\n",
              "         -8.50679353e-04, -4.80103481e-04,  2.04198644e-03],\n",
              "        [-2.81005981e-03, -4.03085677e-03, -1.37614144e-03, ...,\n",
              "         -7.74373475e-04, -4.28662956e-04,  1.99246290e-03],\n",
              "        [-3.32592777e-03, -4.47462406e-03, -1.45621598e-03, ...,\n",
              "         -6.66609907e-04, -4.10856941e-04,  1.90932804e-03]],\n",
              "\n",
              "       [[-4.65645018e-04,  2.70456192e-04,  2.13819541e-04, ...,\n",
              "         -1.05143808e-04,  4.81698735e-05, -1.27589170e-04],\n",
              "        [-6.06664282e-04,  7.26586150e-04,  5.03845513e-04, ...,\n",
              "         -9.43372870e-05, -1.85698620e-04, -2.81145156e-04],\n",
              "        [-5.22335875e-04,  9.21918079e-04,  1.95468980e-04, ...,\n",
              "         -1.44817997e-04, -1.05200270e-04, -2.94399884e-04],\n",
              "        ...,\n",
              "        [-4.85247467e-03, -5.79113979e-03, -1.72295084e-03, ...,\n",
              "         -7.67832797e-04, -1.14364506e-04,  5.70682751e-04],\n",
              "        [-5.16842306e-03, -6.23668963e-03, -1.81991444e-03, ...,\n",
              "         -6.00978034e-04, -2.25749856e-04,  5.81696979e-04],\n",
              "        [-5.42981317e-03, -6.62868656e-03, -1.89933274e-03, ...,\n",
              "         -4.52857552e-04, -3.35733785e-04,  5.81235101e-04]],\n",
              "\n",
              "       [[-4.65645018e-04,  2.70456192e-04,  2.13819541e-04, ...,\n",
              "         -1.05143808e-04,  4.81698735e-05, -1.27589170e-04],\n",
              "        [-6.59785641e-04,  6.48467278e-04,  2.64839444e-04, ...,\n",
              "         -1.30157539e-04, -8.52559824e-05,  1.36730858e-04],\n",
              "        [-3.96139396e-04,  3.39303864e-04,  1.54329493e-04, ...,\n",
              "         -1.88826030e-04, -6.37217949e-04,  1.24922401e-04],\n",
              "        ...,\n",
              "        [-3.04452702e-03, -3.36244004e-03, -4.01550235e-04, ...,\n",
              "         -1.53559613e-05,  4.72085492e-04,  6.71569258e-04],\n",
              "        [-3.65066365e-03, -3.94559093e-03, -6.34251221e-04, ...,\n",
              "         -5.77874162e-05,  3.83587176e-04,  6.71545102e-04],\n",
              "        [-4.17977665e-03, -4.49934462e-03, -8.52985482e-04, ...,\n",
              "         -7.00201053e-05,  2.79372995e-04,  6.62616512e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-4.65645018e-04,  2.70456192e-04,  2.13819541e-04, ...,\n",
              "         -1.05143808e-04,  4.81698735e-05, -1.27589170e-04],\n",
              "        [-5.74071542e-04,  1.44507620e-04,  1.94976092e-04, ...,\n",
              "         -2.87501665e-04, -3.40110040e-04,  4.82113046e-06],\n",
              "        [-6.10671297e-04, -7.94401785e-05, -1.03494858e-04, ...,\n",
              "         -1.93442975e-04, -5.22658927e-04, -9.48001034e-05],\n",
              "        ...,\n",
              "        [-4.75640316e-03, -5.51943621e-03, -1.82958075e-03, ...,\n",
              "         -8.83787579e-04,  8.21366048e-05,  8.96512298e-04],\n",
              "        [-5.11279702e-03, -5.91346342e-03, -1.91944174e-03, ...,\n",
              "         -7.35393667e-04,  2.42406586e-05,  8.22079601e-04],\n",
              "        [-5.40744653e-03, -6.27398212e-03, -1.99413789e-03, ...,\n",
              "         -5.95410995e-04, -5.33330640e-05,  7.51800777e-04]],\n",
              "\n",
              "       [[-4.65645018e-04,  2.70456192e-04,  2.13819541e-04, ...,\n",
              "         -1.05143808e-04,  4.81698735e-05, -1.27589170e-04],\n",
              "        [-6.88451051e-04,  2.06455894e-04,  4.75269189e-04, ...,\n",
              "          1.86929901e-04,  2.06636090e-04, -2.03059826e-04],\n",
              "        [-8.05856311e-04,  1.79418043e-04,  6.56300865e-04, ...,\n",
              "          2.45546340e-04,  3.42565705e-04, -3.26342764e-04],\n",
              "        ...,\n",
              "        [-6.04535872e-03, -7.03580212e-03, -1.97760435e-03, ...,\n",
              "          8.30913814e-06, -4.95002372e-04,  2.75002909e-04],\n",
              "        [-6.13582600e-03, -7.30745168e-03, -2.03813473e-03, ...,\n",
              "          4.37870185e-05, -5.94289275e-04,  2.86463939e-04],\n",
              "        [-6.20476715e-03, -7.54137617e-03, -2.08538841e-03, ...,\n",
              "          7.21847900e-05, -6.85035367e-04,  2.95077218e-04]],\n",
              "\n",
              "       [[-4.65645018e-04,  2.70456192e-04,  2.13819541e-04, ...,\n",
              "         -1.05143808e-04,  4.81698735e-05, -1.27589170e-04],\n",
              "        [-4.40527132e-04,  4.75418965e-05,  3.64477310e-04, ...,\n",
              "         -1.39227632e-04, -3.25588073e-04, -3.69102752e-04],\n",
              "        [-5.76879014e-04, -3.68780456e-04,  9.34021518e-05, ...,\n",
              "         -5.00110327e-05, -2.55886087e-04, -4.43024561e-04],\n",
              "        ...,\n",
              "        [-5.53462980e-03, -6.12100586e-03, -1.68274343e-03, ...,\n",
              "         -3.67096043e-04, -2.68108968e-04,  5.53781632e-04],\n",
              "        [-5.74777322e-03, -6.45352621e-03, -1.79877167e-03, ...,\n",
              "         -2.78081105e-04, -3.44852568e-04,  5.23867842e-04],\n",
              "        [-5.91652188e-03, -6.75564772e-03, -1.89425005e-03, ...,\n",
              "         -1.97885180e-04, -4.24894679e-04,  4.97917063e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "model(src_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ftfQqKICdP",
        "outputId": "028960e2-bf41-452b-9e48-51feb257a1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  7680512   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  20979712  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  33562624  \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  30737049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,959,897\n",
            "Trainable params: 92,959,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3ugFEqRC04x",
        "outputId": "396c2166-a008-4066-c06f-ab126f4457d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "549/549 [==============================] - 208s 372ms/step - loss: 2.7571 - val_loss: 2.4540\n",
            "Epoch 2/10\n",
            "549/549 [==============================] - 204s 372ms/step - loss: 2.2802 - val_loss: 2.2024\n",
            "Epoch 3/10\n",
            "549/549 [==============================] - 204s 372ms/step - loss: 2.0212 - val_loss: 2.0546\n",
            "Epoch 4/10\n",
            "549/549 [==============================] - 203s 370ms/step - loss: 1.7749 - val_loss: 1.9469\n",
            "Epoch 5/10\n",
            "549/549 [==============================] - 203s 370ms/step - loss: 1.5469 - val_loss: 1.8756\n",
            "Epoch 6/10\n",
            "549/549 [==============================] - 203s 369ms/step - loss: 1.3437 - val_loss: 1.8265\n",
            "Epoch 7/10\n",
            "549/549 [==============================] - 203s 370ms/step - loss: 1.1692 - val_loss: 1.7979\n",
            "Epoch 8/10\n",
            "549/549 [==============================] - 203s 370ms/step - loss: 1.0244 - val_loss: 1.7897\n",
            "Epoch 9/10\n",
            "549/549 [==============================] - 203s 370ms/step - loss: 0.9117 - val_loss: 1.8007\n",
            "Epoch 10/10\n",
            "549/549 [==============================] - 203s 370ms/step - loss: 0.8307 - val_loss: 1.8147\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7407a1e610>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer, )\n",
        "model.fit(dataset, validation_data=val_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VGdz4fxXzSHp"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        predict = model(test_tensor) \n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]  \n",
        "\n",
        "         \n",
        "        test_tensor = tf.concat([test_tensor, \n",
        "                                                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "\n",
        "        \n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "\n",
        "     \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "h6R8ZX3I1cht",
        "outputId": "e1ddcae6-6545-4e75-ab35-856853ed0c22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> money and blood dont mix like dicks and no bitch <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> money\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#회고\n",
        "이번에 학습을 시키면서 시간이 오래걸리는 것을 보면서 와.. 이제 드디어 시작이구나 진짜 학습을 시키는거구나를 느꼈다.  \n",
        "처음에 학습을 시켰을때는 embedding_size를 1024로 hidden_size를 2048로 하여 학습을 진행하였으나 2.3 이하로 내려가지 않아서 당황했다. 그래서 embedding_size와 hidden_size를 엄청나게 늘렸으나 오히려 값이 올라서 이게 뭔가 싶었다. 그래서 다른분들께 조언을 구하여 단어장의 갯수를 12000에서 15000으로 늘렸고, 2000까지 늘렸던 embedding_size를 512로 낮추고 hidden_size를 2048로 다시 줄렸다. 그 결과 1.8까지 내려갈 수 있었다.  \n",
        "\n",
        "이번 익스를 진행하면서도 코드를 짜는 것이 여전히 어려웠다. 개념적으로 부족하다고 판단하여서 이 부분에 대한 개념을 반복 숙달 해야할 것 같다."
      ],
      "metadata": {
        "id": "0WgrRqG-22rw"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "작사가 인공지능 만들기.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}