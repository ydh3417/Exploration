{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dtfbqurtEKC2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "5xCmz8PDEPO8",
        "outputId": "53008f98-0a05-4f16-c779-f065e8dfe9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 194513\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          eng  \\\n",
              "131462      Where were you yesterday at 2:30?   \n",
              "19158                       I'm a doctor now.   \n",
              "147477  From now on, let's only speak French.   \n",
              "120732       He always borrows money from me.   \n",
              "148347  I just want to finish this and leave.   \n",
              "\n",
              "                                                      fra  \\\n",
              "131462                       Où étais-tu hier à 14 h 30 ?   \n",
              "19158                         Je suis médecin maintenant.   \n",
              "147477  À partir de maintenant, on ne parle que français.   \n",
              "120732                Il m'emprunte toujours de l'argent.   \n",
              "148347            Je veux seulement finir ceci et partir.   \n",
              "\n",
              "                                                       cc  \n",
              "131462  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
              "19158   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "147477  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
              "120732  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
              "148347  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4e883de-8203-478d-b975-4d6a8a0d2aeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131462</th>\n",
              "      <td>Where were you yesterday at 2:30?</td>\n",
              "      <td>Où étais-tu hier à 14 h 30 ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19158</th>\n",
              "      <td>I'm a doctor now.</td>\n",
              "      <td>Je suis médecin maintenant.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147477</th>\n",
              "      <td>From now on, let's only speak French.</td>\n",
              "      <td>À partir de maintenant, on ne parle que français.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120732</th>\n",
              "      <td>He always borrows money from me.</td>\n",
              "      <td>Il m'emprunte toujours de l'argent.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148347</th>\n",
              "      <td>I just want to finish this and leave.</td>\n",
              "      <td>Je veux seulement finir ceci et partir.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4e883de-8203-478d-b975-4d6a8a0d2aeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4e883de-8203-478d-b975-4d6a8a0d2aeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4e883de-8203-478d-b975-4d6a8a0d2aeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "file_path = (\"/content/drive/MyDrive/Colab Notebooks/tran_make_it/fra.txt\")\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MyfqyoTsEXhG",
        "outputId": "75d8597b-0c68-4fc2-e5e7-7fa7689e2abb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       eng                           fra\n",
              "860             Calm down!                 Calmez-vous !\n",
              "3670          Now I'm sad.  Maintenant je suis attristé.\n",
              "31722  The story wandered.           L'histoire déviait.\n",
              "18329    I can't stop Tom.   Je ne peux pas stopper Tom.\n",
              "358               Kill it.                       Tue-la."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d7e23c0-2c18-4c4c-908d-2665ee687ff9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>Calm down!</td>\n",
              "      <td>Calmez-vous !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3670</th>\n",
              "      <td>Now I'm sad.</td>\n",
              "      <td>Maintenant je suis attristé.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31722</th>\n",
              "      <td>The story wandered.</td>\n",
              "      <td>L'histoire déviait.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18329</th>\n",
              "      <td>I can't stop Tom.</td>\n",
              "      <td>Je ne peux pas stopper Tom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>Kill it.</td>\n",
              "      <td>Tue-la.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d7e23c0-2c18-4c4c-908d-2665ee687ff9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d7e23c0-2c18-4c4c-908d-2665ee687ff9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d7e23c0-2c18-4c4c-908d-2665ee687ff9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "lines = lines[['eng', 'fra']][:33000] # 3만3천개 샘플 사용\n",
        "lines.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "joxnmQvqEgzq"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "  \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!]+\", \" \", sentence)\n",
        "    \n",
        "    sentence = sentence.strip()\n",
        "    sentence = sentence.split(\" \")\n",
        "    \n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FI9N-mG1EioE"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence_decoder(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "  \n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!]+\", \" \", sentence)\n",
        "    \n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    sentence = sentence.split(\" \")\n",
        "    \n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PfSz5ZqwEkgo"
      },
      "outputs": [],
      "source": [
        "lines.eng = lines.eng.apply(lambda x : preprocess_sentence(x))\n",
        "lines.fra = lines.fra.apply(lambda x : preprocess_sentence_decoder(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rag-SSQEEl4Z",
        "outputId": "ef9770e6-dc3e-402d-eae8-3542acb7b8fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30445    [i, m, writing, a, song, .]\n",
              "20631        [they, re, upstairs, .]\n",
              "1802                [face, facts, !]\n",
              "13180        [come, and, get, it, .]\n",
              "9911           [french, is, easy, .]\n",
              "Name: eng, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "lines.eng.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHl8xlDiEnMP",
        "outputId": "c5c05862-028c-423a-bba8-4226e2c647c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5602        [<start>, hasarde, une, hypoth, se, !, <end>]\n",
              "15479           [<start>, elle, l, a, r, veill, ., <end>]\n",
              "15616            [<start>, c, est, mon, argent, ., <end>]\n",
              "21410    [<start>, nous, travaillons, ensemble, ., <end>]\n",
              "4819             [<start>, je, pourrais, aider, ., <end>]\n",
              "Name: fra, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "lines.fra.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YzWqVQFAEpBQ"
      },
      "outputs": [],
      "source": [
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(lines.eng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0vyyy_GEv6V",
        "outputId": "9f6f544d-ebf1-4b63-ba88-eb939b605fb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[29, 1], [29, 1], [29, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "input_text[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3vL9VR6TEzrv"
      },
      "outputs": [],
      "source": [
        "fra_tokenizer = Tokenizer()\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs-7PO_ME1MS",
        "outputId": "15ee102a-d365-4dca-fc90-01e9c1453a5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 75, 8, 2], [1, 378, 3, 2], [1, 718, 8, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "target_text[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3_jdXL8E26z",
        "outputId": "bdf23103-938a-4b48-c3d0-9f7b047a7afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어장의 크기 : 4671\n",
            "프랑스어 단어장의 크기 : 7460\n"
          ]
        }
      ],
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozTTxY1zE403",
        "outputId": "f6c94d47-475f-432b-df3b-b38a65c561c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 시퀀스의 최대 길이 8\n",
            "프랑스어 시퀀스의 최대 길이 17\n"
          ]
        }
      ],
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL-EeunmE6ZO",
        "outputId": "d9a5f30e-17ab-4069-9c00-fa6862a5f92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 33000\n",
            "영어 단어장의 크기 : 4671\n",
            "프랑스어 단어장의 크기 : 7460\n",
            "영어 시퀀스의 최대 길이 8\n",
            "프랑스어 시퀀스의 최대 길이 17\n"
          ]
        }
      ],
      "source": [
        "print('전체 샘플의 수 :',len(lines))\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VDMt5StZE8On"
      },
      "outputs": [],
      "source": [
        "sos_token = '<start>'\n",
        "eos_token = '<end>'\n",
        "\n",
        "encoder_input = input_text\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gft46UfcE90s",
        "outputId": "df8386d2-8323-4acd-f7ca-c132732ef74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 데이터의 크기(shape) : (33000, 8)\n",
            "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
            "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n"
          ]
        }
      ],
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
        "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RMP3-lwtE_bj"
      },
      "outputs": [],
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEjQzLn8FBYS",
        "outputId": "08b7e120-0e57-4b63-cabe-1463d8080200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 8)\n",
            "(30000, 17)\n",
            "(30000, 17)\n",
            "(3000, 8)\n",
            "(3000, 17)\n",
            "(3000, 17)\n"
          ]
        }
      ],
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HhXEF8_jFDUP"
      },
      "outputs": [],
      "source": [
        "embedding_size = 512\n",
        "hidden_size = 512\n",
        "# 인코더에서 사용할 임베딩 층 사용 예시\n",
        "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
        "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
        "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
        "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "57ONTFcTFFMJ"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
        "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "metadata": {
        "id": "0srA3OBLjc9U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "7AmFux4-jfa0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3-r9qfBFGuH",
        "outputId": "2a5123f9-13ca-430a-a5a7-8494e65d0e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 512)    2391552     ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 512)    3819520     ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, None, 512)    0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, None, 512)    0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 512),        2099200     ['masking[0][0]']                \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 512),  2099200     ['masking_1[0][0]',              \n",
            "                                 (None, 512),                     'lstm[0][1]',                   \n",
            "                                 (None, 512)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 7460)   3826980     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,236,452\n",
            "Trainable params: 14,236,452\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "z1_aJq8zFJOo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfjvOGilFLLy",
        "outputId": "cc598b02-8661-492a-d236-ee8a07048a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 35s 28ms/step - loss: 1.3665 - acc: 0.7873 - val_loss: 1.1417 - val_acc: 0.8199\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.0418 - acc: 0.8330 - val_loss: 0.9957 - val_acc: 0.8414\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.9195 - acc: 0.8487 - val_loss: 0.9169 - val_acc: 0.8510\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.8362 - acc: 0.8601 - val_loss: 0.8608 - val_acc: 0.8594\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.7743 - acc: 0.8692 - val_loss: 0.8259 - val_acc: 0.8658\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.7241 - acc: 0.8776 - val_loss: 0.8008 - val_acc: 0.8698\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.6853 - acc: 0.8847 - val_loss: 0.7848 - val_acc: 0.8735\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.6540 - acc: 0.8910 - val_loss: 0.7753 - val_acc: 0.8765\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.6322 - acc: 0.8960 - val_loss: 0.7666 - val_acc: 0.8792\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.6180 - acc: 0.9006 - val_loss: 0.7802 - val_acc: 0.8796\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.6103 - acc: 0.9042 - val_loss: 0.7790 - val_acc: 0.8811\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5913 - acc: 0.9080 - val_loss: 0.7742 - val_acc: 0.8835\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5797 - acc: 0.9104 - val_loss: 0.7632 - val_acc: 0.8837\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5624 - acc: 0.9133 - val_loss: 0.7656 - val_acc: 0.8850\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.5575 - acc: 0.9156 - val_loss: 0.7684 - val_acc: 0.8857\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5528 - acc: 0.9172 - val_loss: 0.7701 - val_acc: 0.8856\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5425 - acc: 0.9194 - val_loss: 0.7703 - val_acc: 0.8860\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5358 - acc: 0.9209 - val_loss: 0.7710 - val_acc: 0.8864\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.5282 - acc: 0.9215 - val_loss: 0.7590 - val_acc: 0.8868\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5138 - acc: 0.9233 - val_loss: 0.7597 - val_acc: 0.8871\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5116 - acc: 0.9243 - val_loss: 0.7591 - val_acc: 0.8883\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5090 - acc: 0.9250 - val_loss: 0.7612 - val_acc: 0.8874\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5068 - acc: 0.9255 - val_loss: 0.7660 - val_acc: 0.8869\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5035 - acc: 0.9262 - val_loss: 0.7645 - val_acc: 0.8864\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4990 - acc: 0.9268 - val_loss: 0.7648 - val_acc: 0.8877\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4950 - acc: 0.9276 - val_loss: 0.7658 - val_acc: 0.8874\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4906 - acc: 0.9278 - val_loss: 0.7644 - val_acc: 0.8874\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.4862 - acc: 0.9285 - val_loss: 0.7620 - val_acc: 0.8871\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4827 - acc: 0.9291 - val_loss: 0.7649 - val_acc: 0.8883\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4789 - acc: 0.9297 - val_loss: 0.7635 - val_acc: 0.8877\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4755 - acc: 0.9298 - val_loss: 0.7626 - val_acc: 0.8880\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4712 - acc: 0.9305 - val_loss: 0.7654 - val_acc: 0.8879\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4688 - acc: 0.9309 - val_loss: 0.7639 - val_acc: 0.8875\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4659 - acc: 0.9312 - val_loss: 0.7595 - val_acc: 0.8874\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4624 - acc: 0.9315 - val_loss: 0.7601 - val_acc: 0.8883\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.4599 - acc: 0.9321 - val_loss: 0.7613 - val_acc: 0.8887\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.4572 - acc: 0.9323 - val_loss: 0.7622 - val_acc: 0.8877\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4547 - acc: 0.9326 - val_loss: 0.7648 - val_acc: 0.8890\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.4520 - acc: 0.9330 - val_loss: 0.7616 - val_acc: 0.8885\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4495 - acc: 0.9331 - val_loss: 0.7634 - val_acc: 0.8876\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4475 - acc: 0.9334 - val_loss: 0.7635 - val_acc: 0.8878\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4448 - acc: 0.9336 - val_loss: 0.7612 - val_acc: 0.8874\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4433 - acc: 0.9336 - val_loss: 0.7603 - val_acc: 0.8881\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4428 - acc: 0.9337 - val_loss: 0.7641 - val_acc: 0.8888\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4412 - acc: 0.9341 - val_loss: 0.7583 - val_acc: 0.8882\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.4401 - acc: 0.9342 - val_loss: 0.7591 - val_acc: 0.8874\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4392 - acc: 0.9344 - val_loss: 0.7619 - val_acc: 0.8875\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4389 - acc: 0.9341 - val_loss: 0.7572 - val_acc: 0.8885\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4391 - acc: 0.9345 - val_loss: 0.7617 - val_acc: 0.8884\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4376 - acc: 0.9345 - val_loss: 0.7646 - val_acc: 0.8874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a2012eb90>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.fit([encoder_input_train, decoder_input_train],decoder_target_train,\n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size = 32, epochs = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBx2XwyrFWit",
        "outputId": "c50bbb37-db07-45e4-dd7b-30dfc037c131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 512)         2391552   \n",
            "                                                                 \n",
            " masking (Masking)           (None, None, 512)         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 512),             2099200   \n",
            "                              (None, 512),                       \n",
            "                              (None, 512)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,490,752\n",
            "Trainable params: 4,490,752\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
        "encoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IB2kKdONFX9V"
      },
      "outputs": [],
      "source": [
        "decoder_state_input_h = Input(shape=(embedding_size,))\n",
        "decoder_state_input_c = Input(shape=(embedding_size,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpSaU2ebFZku",
        "outputId": "bef77ef4-5573-49eb-c54b-8635de0585ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 512)    3819520     ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 512),  2099200     ['embedding_2[0][0]',            \n",
            "                                 (None, 512),                     'input_1[0][0]',                \n",
            "                                 (None, 512)]                     'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 7460)   3826980     ['lstm_1[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,745,700\n",
            "Trainable params: 9,745,700\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
        "decoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jeLNVXADFbOc"
      },
      "outputs": [],
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0XkDYydWFf-2"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = fra2idx['<start>']\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<end>' or\n",
        "           len(decoded_sentence) > max_fra_seq_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wdWrZXZUFjCv"
      },
      "outputs": [],
      "source": [
        "def seq2src(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            temp = temp + idx2eng[i]+' '\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Mx8TNyr6FldB"
      },
      "outputs": [],
      "source": [
        "def seq2tar(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
        "            temp = temp + idx2fra[i] + ' '\n",
        "    return temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4_K4VQqFnXl",
        "outputId": "4186aa7d-edf2-43bb-b43b-fcce5897306e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "입력 문장: i m not even tired . \n",
            "정답 문장: je ne suis m me pas fatigu e . \n",
            "번역기가 번역한 문장:  je ne ne me me . \n",
            "-----------------------------------\n",
            "입력 문장: i m depressed . \n",
            "정답 문장: je d prime . \n",
            "번역기가 번역한 문장:  je suis d d d e \n",
            "-----------------------------------\n",
            "입력 문장: does this hurt ? \n",
            "정답 문장: est ce que a fait mal ? \n",
            "번역기가 번역한 문장:  est ce t mal ? ? \n",
            "-----------------------------------\n",
            "입력 문장: i m not done . \n",
            "정답 문장: je n en ai pas termin . \n",
            "번역기가 번역한 문장:  je n que pas pas \n",
            "-----------------------------------\n",
            "입력 문장: i think you did it . \n",
            "정답 문장: je pense que tu l as fait . \n",
            "번역기가 번역한 문장:  je pense que qui \n"
          ]
        }
      ],
      "source": [
        "for seq_index in [1,100,301,777,2222]:\n",
        "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
        "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고"
      ],
      "metadata": {
        "id": "KHvtz8K9yH9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음에 hidden_size를 넣지 않고 진행을 했더니 번역에서 나오지 않는 부분이 꽤 많았다. 이후 hidden_size를 추가해서 진행해보니 번역이 제대로 진행되었다."
      ],
      "metadata": {
        "id": "zwWJVUSXyKP1"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "번역기를_만들어보자.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}